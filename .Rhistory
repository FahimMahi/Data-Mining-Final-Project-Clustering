nb_predictions <- predict(nb_model, test_data)
# Convert predictions to factors with the same levels as the target
nb_predictions <- factor(nb_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_nb <- confusionMatrix(nb_predictions, test_data$target)
# Print confusion matrix
print(confusion_nb)
# Plot confusion matrix
plot_confusion_matrix(confusion_nb, "Naïve Bayes Confusion Matrix")
# Train SVM model
svm_model <- svm(target ~ ., data = train_data, probability = TRUE)
# Predict and evaluate
svm_predictions <- predict(svm_model, test_data, probability = TRUE)
# Convert predictions to factors with the same levels as the target
svm_predictions <- factor(svm_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_svm <- confusionMatrix(svm_predictions, test_data$target)
# Print confusion matrix
print(confusion_svm)
# Plot confusion matrix
plot_confusion_matrix(confusion_svm, "SVM Confusion Matrix")
# Load necessary libraries
library(dplyr)
library(caret)
library(ggplot2)
library(corrplot)
library(cluster)
library(factoextra)
library(e1071)
library(rpart)
# Load dataset
data <- read.csv("C:/Users/h/Downloads/Data Mining Final/heart (1).csv")
# Display the structure of the dataset
str(data)
# Display the column names
head(data)
# Display the summary statistics of the dataset
summary(data)
# Check for duplicate values in the dataset
sum(duplicated(data))
# Convert categorical variables to factors
categorical_columns <- c('sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal')
data[categorical_columns] <- lapply(data[categorical_columns], as.factor)
# Scale numerical columns
numerical_columns <- c('age', 'trestbps', 'chol', 'thalach', 'oldpeak')
data[numerical_columns] <- scale(data[numerical_columns])
# Split dataset into training and test sets
set.seed(42)
train_indices <- createDataPartition(data$target, p = 0.7, list = FALSE)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Ensure target variable is a factor
train_data$target <- factor(train_data$target)
test_data$target <- factor(test_data$target)
# Distribution of target variable
ggplot(train_data, aes(x = target)) +
geom_bar(fill = "skyblue") +
ggtitle("Distribution of Target Variable") +
theme_minimal()
# Correlation matrix
cor_matrix <- cor(train_data %>% select(all_of(numerical_columns)) %>% as.data.frame())
corrplot(cor_matrix, method = "circle")
# Distributions of selected numerical features
for (feature in numerical_columns) {
print(
ggplot(train_data, aes_string(x = feature)) +
geom_histogram(fill = "blue", alpha = 0.7, bins = 30) +
ggtitle(paste("Distribution of", feature)) +
theme_minimal()
)
}
# Perform PCA to reduce dimensions
pca <- prcomp(train_data[, numerical_columns], scale. = TRUE)
train_data_pca <- pca$x[, 1:2]  # Use the first two principal components
# K-means clustering
set.seed(42)
kmeans_result <- kmeans(train_data_pca, centers = 3)
# K-means clustering
set.seed(42)
kmeans_result <- kmeans(train_data[, numerical_columns], centers = 3)
fviz_cluster(kmeans_result, data = train_data[, numerical_columns])
# Train Decision Tree model
tree_model <- rpart(target ~ ., data = train_data, method = "class")
# Predict and evaluate
tree_predictions <- predict(tree_model, test_data, type = "class")
# Convert predictions to factors with the same levels as the target
tree_predictions <- factor(tree_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_tree <- confusionMatrix(tree_predictions, test_data$target)
# Print confusion matrix
print(confusion_tree)
# Function to plot confusion matrix
plot_confusion_matrix <- function(cm, title) {
cm_data <- as.data.frame(cm$table)
ggplot(data = cm_data, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "black", size = 4) +
scale_fill_gradient(low = "white", high = "red") +
ggtitle(title) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
# Plot confusion matrix
plot_confusion_matrix(confusion_tree, "Decision Tree Confusion Matrix")
# Train Naïve Bayes model
nb_model <- naiveBayes(target ~ ., data = train_data)
# Predict and evaluate
nb_predictions <- predict(nb_model, test_data)
# Convert predictions to factors with the same levels as the target
nb_predictions <- factor(nb_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_nb <- confusionMatrix(nb_predictions, test_data$target)
# Print confusion matrix
print(confusion_nb)
# Plot confusion matrix
plot_confusion_matrix(confusion_nb, "Naïve Bayes Confusion Matrix")
# Train SVM model
svm_model <- svm(target ~ ., data = train_data, probability = TRUE)
# Predict and evaluate
svm_predictions <- predict(svm_model, test_data, probability = TRUE)
# Convert predictions to factors with the same levels as the target
svm_predictions <- factor(svm_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_svm <- confusionMatrix(svm_predictions, test_data$target)
# Print confusion matrix
print(confusion_svm)
# Plot confusion matrix
plot_confusion_matrix(confusion_svm, "SVM Confusion Matrix")
# Print confusion matrix
print(confusion_nb)
# Plot confusion matrix
plot_confusion_matrix(confusion_nb, "Naïve Bayes Confusion Matrix")
fviz_cluster(kmeans_result, data = train_data[, numerical_columns])
# Load necessary libraries
library(dplyr)
library(caret)
library(ggplot2)
library(corrplot)
library(cluster)
library(factoextra)
library(e1071)
library(rpart)
# Load dataset
data <- read.csv("C:/Users/h/Downloads/Data Mining Final/heart (1).csv")
# Display the structure of the dataset
str(data)
# Display the column names
head(data)
# Display the summary statistics of the dataset
summary(data)
# Check for duplicate values in the dataset
sum(duplicated(data))
# Convert categorical variables to factors
categorical_columns <- c('sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal')
data[categorical_columns] <- lapply(data[categorical_columns], as.factor)
# Scale numerical columns
numerical_columns <- c('age', 'trestbps', 'chol', 'thalach', 'oldpeak')
data[numerical_columns] <- scale(data[numerical_columns])
# Split dataset into training and test sets
set.seed(42)
train_indices <- createDataPartition(data$target, p = 0.7, list = FALSE)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Ensure target variable is a factor
train_data$target <- factor(train_data$target)
test_data$target <- factor(test_data$target)
# Distribution of target variable
ggplot(train_data, aes(x = target)) +
geom_bar(fill = "skyblue") +
ggtitle("Distribution of Target Variable") +
theme_minimal()
# Correlation matrix
cor_matrix <- cor(train_data %>% select(all_of(numerical_columns)) %>% as.data.frame())
corrplot(cor_matrix, method = "circle")
# Distributions of selected numerical features
for (feature in numerical_columns) {
print(
ggplot(train_data, aes_string(x = feature)) +
geom_histogram(fill = "blue", alpha = 0.7, bins = 30) +
ggtitle(paste("Distribution of", feature)) +
theme_minimal()
)
}
# K-means clustering
set.seed(42)
kmeans_result <- kmeans(train_data[, numerical_columns], centers = 3)
fviz_cluster(kmeans_result, data = train_data[, numerical_columns])
# Train Decision Tree model
tree_model <- rpart(target ~ ., data = train_data, method = "class")
# Predict and evaluate
tree_predictions <- predict(tree_model, test_data, type = "class")
# Convert predictions to factors with the same levels as the target
tree_predictions <- factor(tree_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_tree <- confusionMatrix(tree_predictions, test_data$target)
# Print confusion matrix
print(confusion_tree)
# Function to plot confusion matrix
plot_confusion_matrix <- function(cm, title) {
cm_data <- as.data.frame(cm$table)
ggplot(data = cm_data, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "black", size = 4) +
scale_fill_gradient(low = "white", high = "red") +
ggtitle(title) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
# Plot confusion matrix
plot_confusion_matrix(confusion_tree, "Decision Tree Confusion Matrix")
# Train Naïve Bayes model
nb_model <- naiveBayes(target ~ ., data = train_data)
# Predict and evaluate
nb_predictions <- predict(nb_model, test_data)
# Convert predictions to factors with the same levels as the target
nb_predictions <- factor(nb_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_nb <- confusionMatrix(nb_predictions, test_data$target)
# Print confusion matrix
print(confusion_nb)
# Plot confusion matrix
plot_confusion_matrix(confusion_nb, "Naïve Bayes Confusion Matrix")
# Train SVM model
svm_model <- svm(target ~ ., data = train_data, probability = TRUE)
# Predict and evaluate
svm_predictions <- predict(svm_model, test_data, probability = TRUE)
# Convert predictions to factors with the same levels as the target
svm_predictions <- factor(svm_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_svm <- confusionMatrix(svm_predictions, test_data$target)
# Print confusion matrix
print(confusion_svm)
# Plot confusion matrix
plot_confusion_matrix(confusion_svm, "SVM Confusion Matrix")
# Load necessary libraries
library(dplyr)
library(caret)
library(ggplot2)
library(corrplot)
library(cluster)
library(factoextra)
library(e1071)
library(rpart)
# Load dataset
data <- read.csv("C:/Users/h/Downloads/Data Mining Final/heart (1).csv")
# Display the structure of the dataset
str(data)
# Display the column names
head(data)
# Display the summary statistics of the dataset
summary(data)
# Check for duplicate values in the dataset
sum(duplicated(data))
# Convert categorical variables to factors
categorical_columns <- c('sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal')
data[categorical_columns] <- lapply(data[categorical_columns], as.factor)
# Scale numerical columns
numerical_columns <- c('age', 'trestbps', 'chol', 'thalach', 'oldpeak')
data[numerical_columns] <- scale(data[numerical_columns])
# Split dataset into training and test sets
set.seed(42)
train_indices <- createDataPartition(data$target, p = 0.7, list = FALSE)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Ensure target variable is a factor
train_data$target <- factor(train_data$target)
test_data$target <- factor(test_data$target)
# Distribution of target variable
ggplot(train_data, aes(x = target)) +
geom_bar(fill = "skyblue") +
ggtitle("Distribution of Target Variable") +
theme_minimal()
# Correlation matrix
cor_matrix <- cor(train_data %>% select(all_of(numerical_columns)) %>% as.data.frame())
corrplot(cor_matrix, method = "circle")
# Distributions of selected numerical features
for (feature in numerical_columns) {
print(
ggplot(train_data, aes_string(x = feature)) +
geom_histogram(fill = "blue", alpha = 0.7, bins = 30) +
ggtitle(paste("Distribution of", feature)) +
theme_minimal()
)
}
# K-means clustering
set.seed(42)
kmeans_result <- kmeans(train_data[, numerical_columns], centers = 3)
fviz_cluster(kmeans_result, data = train_data[, numerical_columns])
# Train Decision Tree model
tree_model <- rpart(target ~ ., data = train_data, method = "class")
# Predict and evaluate
tree_predictions <- predict(tree_model, test_data, type = "class")
# Convert predictions to factors with the same levels as the target
tree_predictions <- factor(tree_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_tree <- confusionMatrix(tree_predictions, test_data$target)
# Print confusion matrix
print(confusion_tree)
# Function to plot confusion matrix
plot_confusion_matrix <- function(cm, title) {
cm_data <- as.data.frame(cm$table)
ggplot(data = cm_data, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "black", size = 4) +
scale_fill_gradient(low = "green", high = "red") +
ggtitle(title) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
# Plot confusion matrix
plot_confusion_matrix(confusion_tree, "Decision Tree Confusion Matrix")
# Load necessary libraries
library(dplyr)
library(caret)
library(ggplot2)
library(corrplot)
library(cluster)
library(factoextra)
library(e1071)
library(rpart)
# Load dataset
data <- read.csv("C:/Users/h/Downloads/Data Mining Final/heart (1).csv")
# Display the structure of the dataset
str(data)
# Display the column names
head(data)
# Display the summary statistics of the dataset
summary(data)
# Check for duplicate values in the dataset
sum(duplicated(data))
# Convert categorical variables to factors
categorical_columns <- c('sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal')
data[categorical_columns] <- lapply(data[categorical_columns], as.factor)
# Scale numerical columns
numerical_columns <- c('age', 'trestbps', 'chol', 'thalach', 'oldpeak')
data[numerical_columns] <- scale(data[numerical_columns])
# Split dataset into training and test sets
set.seed(42)
train_indices <- createDataPartition(data$target, p = 0.7, list = FALSE)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Ensure target variable is a factor
train_data$target <- factor(train_data$target)
test_data$target <- factor(test_data$target)
# Distribution of target variable
ggplot(train_data, aes(x = target)) +
geom_bar(fill = "skyblue") +
ggtitle("Distribution of Target Variable") +
theme_minimal()
# Correlation matrix
cor_matrix <- cor(train_data %>% select(all_of(numerical_columns)) %>% as.data.frame())
corrplot(cor_matrix, method = "circle")
# Distributions of selected numerical features
for (feature in numerical_columns) {
print(
ggplot(train_data, aes_string(x = feature)) +
geom_histogram(fill = "blue", alpha = 0.7, bins = 30) +
ggtitle(paste("Distribution of", feature)) +
theme_minimal()
)
}
# K-means clustering
set.seed(42)
kmeans_result <- kmeans(train_data[, numerical_columns], centers = 3)
fviz_cluster(kmeans_result, data = train_data[, numerical_columns])
# Train Decision Tree model
tree_model <- rpart(target ~ ., data = train_data, method = "class")
# Predict and evaluate
tree_predictions <- predict(tree_model, test_data, type = "class")
# Convert predictions to factors with the same levels as the target
tree_predictions <- factor(tree_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_tree <- confusionMatrix(tree_predictions, test_data$target)
# Print confusion matrix
print(confusion_tree)
# Function to plot confusion matrix
plot_confusion_matrix <- function(cm, title) {
cm_data <- as.data.frame(cm$table)
ggplot(data = cm_data, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "black", size = 4) +
scale_fill_gradient(low = "pink", high = "red") +
ggtitle(title) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
# Plot confusion matrix
plot_confusion_matrix(confusion_tree, "Decision Tree Confusion Matrix")
# Train Naïve Bayes model
nb_model <- naiveBayes(target ~ ., data = train_data)
# Predict and evaluate
nb_predictions <- predict(nb_model, test_data)
# Convert predictions to factors with the same levels as the target
nb_predictions <- factor(nb_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_nb <- confusionMatrix(nb_predictions, test_data$target)
# Print confusion matrix
print(confusion_nb)
# Plot confusion matrix
plot_confusion_matrix(confusion_nb, "Naïve Bayes Confusion Matrix")
svm_model <- svm(target ~ ., data = train_data, probability = TRUE)
# Predict and evaluate
svm_predictions <- predict(svm_model, test_data, probability = TRUE)
# Convert predictions to factors with the same levels as the target
svm_predictions <- factor(svm_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_svm <- confusionMatrix(svm_predictions, test_data$target)
# Print confusion matrix
print(confusion_svm)
# Plot confusion matrix
plot_confusion_matrix(confusion_svm, "SVM Confusion Matrix")
# Load necessary libraries
library(dplyr)
library(caret)
library(ggplot2)
library(corrplot)
library(cluster)
library(factoextra)
library(e1071)
library(rpart)
# Load dataset
data <- read.csv("C:/Users/h/Downloads/Data Mining Final/heart (1).csv")
# Display the structure of the dataset
str(data)
# Display the column names
head(data)
# Display the summary statistics of the dataset
summary(data)
# Check for duplicate values in the dataset
sum(duplicated(data))
# Convert categorical variables to factors
categorical_columns <- c('sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal')
data[categorical_columns] <- lapply(data[categorical_columns], as.factor)
# Scale numerical columns
numerical_columns <- c('age', 'trestbps', 'chol', 'thalach', 'oldpeak')
data[numerical_columns] <- scale(data[numerical_columns])
# Split dataset into training and test sets
set.seed(42)
train_indices <- createDataPartition(data$target, p = 0.7, list = FALSE)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Ensure target variable is a factor
train_data$target <- factor(train_data$target)
test_data$target <- factor(test_data$target)
# Distribution of target variable
ggplot(train_data, aes(x = target)) +
geom_bar(fill = "skyblue") +
ggtitle("Distribution of Target Variable") +
theme_minimal()
# Correlation matrix
cor_matrix <- cor(train_data %>% select(all_of(numerical_columns)) %>% as.data.frame())
corrplot(cor_matrix, method = "circle")
# Distributions of selected numerical features
for (feature in numerical_columns) {
print(
ggplot(train_data, aes_string(x = feature)) +
geom_histogram(fill = "blue", alpha = 0.7, bins = 30) +
ggtitle(paste("Distribution of", feature)) +
theme_minimal()
)
}
# K-means clustering
set.seed(42)
kmeans_result <- kmeans(train_data[, numerical_columns], centers = 3)
fviz_cluster(kmeans_result, data = train_data[, numerical_columns])
# Train Decision Tree model
tree_model <- rpart(target ~ ., data = train_data, method = "class")
# Predict and evaluate
tree_predictions <- predict(tree_model, test_data, type = "class")
# Convert predictions to factors with the same levels as the target
tree_predictions <- factor(tree_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_tree <- confusionMatrix(tree_predictions, test_data$target)
# Print confusion matrix
print(confusion_tree)
# Function to plot confusion matrix
plot_confusion_matrix <- function(cm, title) {
cm_data <- as.data.frame(cm$table)
ggplot(data = cm_data, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "black", size = 4) +
scale_fill_gradient(low = "pink", high = "red") +
ggtitle(title) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
# Plot confusion matrix
plot_confusion_matrix(confusion_tree, "Decision Tree Confusion Matrix")
# Train Naïve Bayes model
nb_model <- naiveBayes(target ~ ., data = train_data)
# Predict and evaluate
nb_predictions <- predict(nb_model, test_data)
# Convert predictions to factors with the same levels as the target
nb_predictions <- factor(nb_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_nb <- confusionMatrix(nb_predictions, test_data$target)
# Print confusion matrix
print(confusion_nb)
# Plot confusion matrix
plot_confusion_matrix(confusion_nb, "Naïve Bayes Confusion Matrix")
# Train SVM model
svm_model <- svm(target ~ ., data = train_data, probability = TRUE)
# Predict and evaluate
svm_predictions <- predict(svm_model, test_data, probability = TRUE)
# Convert predictions to factors with the same levels as the target
svm_predictions <- factor(svm_predictions, levels = levels(test_data$target))
# Evaluate the model with confusion matrix
confusion_svm <- confusionMatrix(svm_predictions, test_data$target)
# Print confusion matrix
print(confusion_svm)
# Plot confusion matrix
plot_confusion_matrix(confusion_svm, "SVM Confusion Matrix")
